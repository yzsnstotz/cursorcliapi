# Copy this file to `.env` (it is gitignored) and edit as needed.
#
# Then start the gateway with:
#   ./scripts/serve.sh

# Optional auth (if set, clients must send: Authorization: Bearer <token>)
CODEX_GATEWAY_TOKEN=devtoken

# Verbose gateway logs: prompt, codex events, response
CODEX_DEBUG_LOG=1
CODEX_LOG_MAX_CHARS=20000

# For clients that parse a single do(...)/finish(...) action (e.g. Open-AutoGLM)
CODEX_STRIP_ANSWER_TAGS=1

# Large prompts / screenshots can make codex JSONL events exceed default asyncio pipe limits
CODEX_SUBPROCESS_STREAM_LIMIT=16777216

# Default model and reasoning
CODEX_MODEL=gpt-5.2
CODEX_MODEL_REASONING_EFFORT=low

# Optional: accept alternative model ids from clients by mapping them to a real Codex model
# CODEX_MODEL_ALIASES={"autoglm-phone":"gpt-5.2"}
# Optional: customize GET /v1/models output
# CODEX_ADVERTISED_MODELS=gpt-5.2,gpt-5-codex

# Optional performance: point Codex at a minimal HOME to avoid starting MCP servers per request
# CODEX_CLI_HOME=/absolute/path/to/.codex-gateway-home
